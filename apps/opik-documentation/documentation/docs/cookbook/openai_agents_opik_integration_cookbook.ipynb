{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c2c58f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# OpenAI Agents with Opik Integration Cookbook\n",
    "\n",
    "This cookbook demonstrates how to integrate OpenAI's Agent framework with Opik for comprehensive observability and monitoring of your AI agents.\n",
    "\n",
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e43488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install opik openai python-dotenv --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8fb6eb",
   "metadata": {},
   "source": [
    "### Configure Opik for your session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c19da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Opik is already configured. You can check the settings by viewing the config file at /home/mavrick/.opik.config\n"
     ]
    }
   ],
   "source": [
    "import opik\n",
    "opik.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e717567",
   "metadata": {},
   "source": [
    "### Set up your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99feaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec4c34",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f6e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opik\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import getpass\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, List, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a028385d",
   "metadata": {},
   "source": [
    "### Enable OpenAI Tracking with Opik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9937823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI client configured with Opik tracking!\n"
     ]
    }
   ],
   "source": [
    "from opik.integrations.openai import track_openai\n",
    "from opik import track\n",
    "\n",
    "\n",
    "# Create tracked OpenAI client\n",
    "openai_client = track_openai(OpenAI())\n",
    "\n",
    "print(\"✅ OpenAI client configured with Opik tracking!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d499786",
   "metadata": {},
   "source": [
    "### Define Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8cffccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tool functions defined!\n"
     ]
    }
   ],
   "source": [
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Mock web search function - replace with actual search implementation\"\"\"\n",
    "    # This is a mock function - in practice, you'd integrate with a real search API\n",
    "    mock_results = {\n",
    "        \"AI safety\": \"Recent developments in AI safety include constitutional AI, RLHF improvements, and new alignment research from major labs.\",\n",
    "        \"machine learning\": \"Latest ML trends include transformer architectures, multimodal models, and efficient training techniques.\",\n",
    "        \"climate change\": \"Current climate research focuses on renewable energy, carbon capture, and climate modeling improvements.\"\n",
    "    }\n",
    "    \n",
    "    # Simple keyword matching for demo\n",
    "    for key in mock_results:\n",
    "        if key.lower() in query.lower():\n",
    "            return mock_results[key]\n",
    "    \n",
    "    return f\"Search results for '{query}': General information about the topic with recent developments and key insights.\"\n",
    "\n",
    "def summarize_content(content: str, max_points: int = 5) -> str:\n",
    "    \"\"\"Mock summarization function\"\"\"\n",
    "    # In practice, you might use another LLM call or summarization service\n",
    "    sentences = content.split('. ')\n",
    "    key_points = sentences[:max_points]\n",
    "    summary = \"Key Points Summary:\\n\"\n",
    "    for i, point in enumerate(key_points, 1):\n",
    "        if point.strip():\n",
    "            summary += f\"{i}. {point.strip()}\\n\"\n",
    "    return summary\n",
    "\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get current time\"\"\"\n",
    "    return f\"Current time: {time.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "print(\"✅ Tool functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de2550",
   "metadata": {},
   "source": [
    "### Create Research Agent Tools Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f299d37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"openai-agents-cookbook\" project at https://www.comet.com/opik/api/v1/session/redirect/projects/?trace_id=0197c48e-baa2-74fe-9e14-ffb5576f05c8&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created 3 tools for the research agent\n"
     ]
    }
   ],
   "source": [
    "@track(project_name=\"openai-agents-cookbook\")\n",
    "def create_research_agent_tools():\n",
    "    \"\"\"Define tools available to the research agent.\"\"\"\n",
    "    \n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"web_search\",\n",
    "                \"description\": \"Search the web for current information on any topic\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query to find relevant information\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"summarize_content\",\n",
    "                \"description\": \"Summarize lengthy content into key points\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"content\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The content to summarize\"\n",
    "                        },\n",
    "                        \"max_points\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Maximum number of summary points\",\n",
    "                            \"default\": 5\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"content\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_time\",\n",
    "                \"description\": \"Get the current date and time\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {},\n",
    "                    \"required\": []\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return tools\n",
    "\n",
    "tools = create_research_agent_tools()\n",
    "print(f\"✅ Created {len(tools)} tools for the research agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f12df",
   "metadata": {},
   "source": [
    "The prompt and response messages are automatically logged to Opik and can be viewed in the UI.\n",
    "\n",
    "![Openai Agents Opik Integration Cookbook](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/openai_agents_opik_integration_cookbook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35474b78",
   "metadata": {},
   "source": [
    "### Simple Research Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256caa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Simple agent function ready!\n"
     ]
    }
   ],
   "source": [
    "@track(project_name=\"openai-agents-cookbook\")\n",
    "def run_simple_agent(user_message: str, model: str = \"gpt-4o-mini\"):\n",
    "    \"\"\"Run a simple research agent conversation\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"You are a helpful research assistant. Use the available tools to provide comprehensive and accurate answers. \n",
    "            \n",
    "            Guidelines:\n",
    "            - Always search for current information when asked about recent developments\n",
    "            - Summarize long content to make it digestible\n",
    "            - Include timestamps when relevant\n",
    "            - Be helpful and thorough in your responses\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    # Make the API call\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    assistant_message = response.choices[0].message\n",
    "    messages.append(assistant_message)\n",
    "    \n",
    "    # Handle tool calls if any\n",
    "    if assistant_message.tool_calls:\n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"🔧 Calling function: {function_name}\")\n",
    "            print(f\"📝 Arguments: {function_args}\")\n",
    "            \n",
    "            # Execute the function\n",
    "            if function_name == \"web_search\":\n",
    "                function_result = web_search(function_args[\"query\"])\n",
    "            elif function_name == \"summarize_content\":\n",
    "                function_result = summarize_content(\n",
    "                    function_args[\"content\"], \n",
    "                    function_args.get(\"max_points\", 5)\n",
    "                )\n",
    "            elif function_name == \"get_current_time\":\n",
    "                function_result = get_current_time()\n",
    "            else:\n",
    "                function_result = f\"Unknown function: {function_name}\"\n",
    "            \n",
    "            print(f\"✅ Function result: {function_result[:100]}...\")\n",
    "            \n",
    "            # Add the function result to the conversation\n",
    "            messages.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_result\n",
    "            })\n",
    "        \n",
    "        # Get final response after tool execution\n",
    "        final_response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return final_response.choices[0].message.content, messages\n",
    "    \n",
    "    return assistant_message.content, messages\n",
    "\n",
    "print(\"✅ Simple agent function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33dfc9f",
   "metadata": {},
   "source": [
    "### Test Simple Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c930a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Calling function: web_search\n",
      "📝 Arguments: {'query': 'latest developments in AI safety research 2023'}\n",
      "✅ Function result: Recent developments in AI safety include constitutional AI, RLHF improvements, and new alignment res...\n",
      "🤖 Agent Response:\n",
      "==================================================\n",
      "Recent developments in AI safety research as of 2023 include several key advancements:\n",
      "\n",
      "1. **Constitutional AI**: This approach aims to guide AI behavior using a set of ethical principles or \"constitution\" rather than relying solely on human-generated instructions. It attempts to create a framework for AI systems to make decisions aligned with human values while allowing for flexibility in interpretation.\n",
      "\n",
      "2. **Improvements in Reinforcement Learning from Human Feedback (RLHF)**: Researchers are refining RLHF techniques to enhance how AI models learn from human input. This includes better methodologies for integrating human preferences into training processes, which could lead to safer and more aligned AI systems.\n",
      "\n",
      "3. **New Alignment Research**: Major AI labs are actively conducting research focused on aligning AI systems with human intentions. This includes exploring advanced techniques for ensuring that AI behavior is predictable and beneficial, as well as addressing potential risks associated with powerful AI technologies.\n",
      "\n",
      "These developments highlight a growing emphasis on creating AI that is not only powerful but also safe and aligned with human values. As AI technology continues to evolve, ongoing research in these areas is crucial to mitigate risks and enhance the reliability of AI systems.\n",
      "==================================================\n",
      "\n",
      "📊 Conversation had 4 messages\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test the simple agent\n",
    "result, conversation = run_simple_agent(\n",
    "    \"What are the latest developments in AI safety research? Please search for current information and summarize the key points.\"\n",
    ")\n",
    "\n",
    "print(\"🤖 Agent Response:\")\n",
    "print(\"=\" * 50)\n",
    "print(result)\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n📊 Conversation had {len(conversation)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c3e99",
   "metadata": {},
   "source": [
    "The prompt and response messages are automatically logged to Opik and can be viewed in the UI.\n",
    "\n",
    "![Openai Agents Opik Integration Simple Agent ](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/openai_agents_opik_integration_cookbook_simple_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bcf2a",
   "metadata": {},
   "source": [
    "###  Advanced Multi-Turn Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae9f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Multi-turn agent function ready!\n"
     ]
    }
   ],
   "source": [
    "@track(project_name=\"openai-agents-cookbook\")\n",
    "def run_multi_turn_agent(user_message: str, max_iterations: int = 5, model: str = \"gpt-4o-mini\"):\n",
    "    \"\"\"Run a multi-turn conversation with the research agent\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"You are an expert research assistant with access to search and summarization tools. \n",
    "\n",
    "            Your approach:\n",
    "            1. Break down complex questions into smaller parts\n",
    "            2. Search for current information when needed\n",
    "            3. Synthesize information from multiple sources\n",
    "            4. Provide well-structured, comprehensive answers\n",
    "            5. Use tools strategically to enhance your responses\n",
    "            \n",
    "            Always be helpful, accurate, and thorough.\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        print(f\"\\n🔄 Iteration {iteration}\")\n",
    "        \n",
    "        # Make the API call\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message\n",
    "        messages.append(assistant_message)\n",
    "        \n",
    "        # Check if the model wants to call a function\n",
    "        if assistant_message.tool_calls:\n",
    "            print(f\"🔧 Agent wants to use {len(assistant_message.tool_calls)} tool(s)\")\n",
    "            \n",
    "            for tool_call in assistant_message.tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                print(f\"   • {function_name}: {function_args}\")\n",
    "                \n",
    "                # Execute the function\n",
    "                if function_name == \"web_search\":\n",
    "                    function_result = web_search(function_args[\"query\"])\n",
    "                elif function_name == \"summarize_content\":\n",
    "                    function_result = summarize_content(\n",
    "                        function_args[\"content\"], \n",
    "                        function_args.get(\"max_points\", 5)\n",
    "                    )\n",
    "                elif function_name == \"get_current_time\":\n",
    "                    function_result = get_current_time()\n",
    "                else:\n",
    "                    function_result = f\"Unknown function: {function_name}\"\n",
    "                \n",
    "                # Add the function result to the conversation\n",
    "                messages.append({\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_result\n",
    "                })\n",
    "        else:\n",
    "            # No more function calls, return the final response\n",
    "            print(\"✅ Agent completed its response\")\n",
    "            return assistant_message.content, messages, iteration\n",
    "    \n",
    "    print(\"⚠️ Max iterations reached\")\n",
    "    return \"Max iterations reached\", messages, iteration\n",
    "\n",
    "print(\"✅ Multi-turn agent function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd4fe7",
   "metadata": {},
   "source": [
    "### Test Multi-Turn Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fdd9616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Iteration 1\n",
      "🔧 Agent wants to use 3 tool(s)\n",
      "   • web_search: {'query': 'recent breakthroughs in AI safety 2023'}\n",
      "   • get_current_time: {}\n",
      "   • web_search: {'query': 'key points artificial intelligence 2023'}\n",
      "\n",
      "🔄 Iteration 2\n",
      "🔧 Agent wants to use 2 tool(s)\n",
      "   • summarize_content: {'content': 'Recent developments in AI safety include constitutional AI, RLHF improvements, and new alignment research from major labs.', 'max_points': 5}\n",
      "   • summarize_content: {'content': 'General information about the topic with recent developments and key insights.', 'max_points': 5}\n",
      "\n",
      "🔄 Iteration 3\n",
      "✅ Agent completed its response\n",
      "🤖 Final Agent Response:\n",
      "============================================================\n",
      "Here's the information you requested for your report on the current state of artificial intelligence:\n",
      "\n",
      "### 1. Recent Breakthroughs in AI Safety\n",
      "Recent developments in AI safety include:\n",
      "- **Constitutional AI**: A new approach to align AI behavior with human values and ethical principles.\n",
      "- **Reinforcement Learning from Human Feedback (RLHF) Improvements**: Enhancements in using human feedback to train AI systems for better decision-making and alignment with human expectations.\n",
      "- **New Alignment Research**: Ongoing research from major labs aimed at ensuring AI systems are aligned with human intentions and safety protocols.\n",
      "\n",
      "### 2. Current Time for Report Timestamp \n",
      "- **Current Time**: 2025-07-01 11:34:54\n",
      "\n",
      "### 3. Summary of Key Points for Executive Summary\n",
      "#### Key Points Related to Artificial Intelligence (2023):\n",
      "1. Recent developments in AI safety include constitutional AI, RLHF improvements, and new alignment research from major labs.\n",
      "2. General information about the topic with recent developments and key insights.\n",
      "\n",
      "If you need more detailed insights or specific examples for any of these points, feel free to ask!\n",
      "============================================================\n",
      "\n",
      "📊 Completed in 3 iterations with 10 total messages\n"
     ]
    }
   ],
   "source": [
    "# Test the multi-turn agent with a complex query\n",
    "complex_query = \"\"\"\n",
    "I'm writing a report on the current state of artificial intelligence. \n",
    "Can you help me gather information on:\n",
    "1. Recent breakthroughs in AI safety\n",
    "2. The current time for my report timestamp\n",
    "3. A summary of the key points for my executive summary\n",
    "\n",
    "Please be thorough and use your tools as needed.\n",
    "\"\"\"\n",
    "\n",
    "result, conversation, iterations = run_multi_turn_agent(complex_query, max_iterations=5)\n",
    "\n",
    "print(\"🤖 Final Agent Response:\")\n",
    "print(\"=\" * 60)\n",
    "print(result)\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n📊 Completed in {iterations} iterations with {len(conversation)} total messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4392a54",
   "metadata": {},
   "source": [
    "The prompt and response messages are automatically logged to Opik and can be viewed in the UI.\n",
    "\n",
    "![openai agents opik integration multi Agent](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/openai_agents_opik_integration_cookbook_multi_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75174520",
   "metadata": {},
   "source": [
    "### Customer Service Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f5822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Customer Service Agent created!\n"
     ]
    }
   ],
   "source": [
    "class CustomerServiceAgent:\n",
    "    def __init__(self, openai_client):\n",
    "        self.client = openai_client\n",
    "        self.tools = self._define_tools()\n",
    "    \n",
    "    def _define_tools(self):\n",
    "        return [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"lookup_order\",\n",
    "                    \"description\": \"Look up customer order information by order ID\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"order_id\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The order ID to lookup (format: ORD-XXX)\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"order_id\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"process_refund\",\n",
    "                    \"description\": \"Process a refund for a customer order\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"order_id\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The order ID for refund\"\n",
    "                            },\n",
    "                            \"amount\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"description\": \"Refund amount in USD\"\n",
    "                            },\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Reason for refund\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"order_id\", \"amount\", \"reason\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"escalate_to_human\",\n",
    "                    \"description\": \"Escalate the conversation to a human agent\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Reason for escalation\"\n",
    "                            },\n",
    "                            \"priority\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"enum\": [\"low\", \"medium\", \"high\"],\n",
    "                                \"description\": \"Priority level for escalation\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"reason\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def lookup_order(self, order_id: str) -> Dict:\n",
    "        \"\"\"Mock order lookup function\"\"\"\n",
    "        time.sleep(0.1)  # Simulate database lookup\n",
    "        mock_orders = {\n",
    "            \"ORD-123\": {\n",
    "                \"status\": \"shipped\",\n",
    "                \"items\": [\"Wireless Laptop\", \"Gaming Mouse\"],\n",
    "                \"total\": 1299.99,\n",
    "                \"tracking\": \"TRK-456789\",\n",
    "                \"shipped_date\": \"2024-01-15\"\n",
    "            },\n",
    "            \"ORD-456\": {\n",
    "                \"status\": \"processing\",\n",
    "                \"items\": [\"Noise-Cancelling Headphones\"],\n",
    "                \"total\": 199.99,\n",
    "                \"tracking\": None,\n",
    "                \"expected_ship\": \"2024-01-20\"\n",
    "            },\n",
    "            \"ORD-789\": {\n",
    "                \"status\": \"delivered\",\n",
    "                \"items\": [\"Smartphone Case\", \"Screen Protector\"],\n",
    "                \"total\": 29.99,\n",
    "                \"tracking\": \"TRK-987654\",\n",
    "                \"delivered_date\": \"2024-01-10\"\n",
    "            }\n",
    "        }\n",
    "        return mock_orders.get(order_id, {\"error\": \"Order not found\"})\n",
    "    \n",
    "    def process_refund(self, order_id: str, amount: float, reason: str) -> Dict:\n",
    "        \"\"\"Mock refund processing function\"\"\"\n",
    "        time.sleep(0.2)  # Simulate processing time\n",
    "        return {\n",
    "            \"refund_id\": f\"REF-{random.randint(1000, 9999)}\",\n",
    "            \"status\": \"processed\",\n",
    "            \"amount\": amount,\n",
    "            \"order_id\": order_id,\n",
    "            \"reason\": reason,\n",
    "            \"estimated_days\": \"3-5 business days\",\n",
    "            \"confirmation_email\": \"sent\"\n",
    "        }\n",
    "    \n",
    "    def escalate_to_human(self, reason: str, priority: str = \"medium\") -> Dict:\n",
    "        \"\"\"Mock escalation function\"\"\"\n",
    "        return {\n",
    "            \"ticket_id\": f\"ESC-{random.randint(10000, 99999)}\",\n",
    "            \"status\": \"escalated\",\n",
    "            \"priority\": priority,\n",
    "            \"reason\": reason,\n",
    "            \"estimated_response\": \"within 2 hours\",\n",
    "            \"agent_assigned\": \"pending\"\n",
    "        }\n",
    "    \n",
    "    @track(project_name=\"openai-agents-cookbook\")\n",
    "    def handle_customer_request(self, customer_message: str, model: str = \"gpt-4o-mini\"):\n",
    "        \"\"\"Handle a customer service request\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a helpful customer service agent. Your goal is to:\n",
    "\n",
    "                1. Understand the customer's issue clearly\n",
    "                2. Use available tools to help resolve their problem\n",
    "                3. Be empathetic and professional\n",
    "                4. Escalate to human agents when necessary\n",
    "                5. Always confirm actions before processing refunds\n",
    "\n",
    "                Available tools:\n",
    "                - lookup_order: Find order information\n",
    "                - process_refund: Process refunds (ask for confirmation first)\n",
    "                - escalate_to_human: Escalate complex issues\n",
    "\n",
    "                Always be polite and helpful!\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": customer_message}\n",
    "        ]\n",
    "        \n",
    "        max_iterations = 3\n",
    "        iteration = 0\n",
    "        \n",
    "        while iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\",\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            assistant_message = response.choices[0].message\n",
    "            messages.append(assistant_message)\n",
    "            \n",
    "            if assistant_message.tool_calls:\n",
    "                for tool_call in assistant_message.tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "                    \n",
    "                    print(f\"🔧 Using tool: {function_name}\")\n",
    "                    \n",
    "                    # Execute the appropriate function\n",
    "                    if function_name == \"lookup_order\":\n",
    "                        result = self.lookup_order(function_args[\"order_id\"])\n",
    "                    elif function_name == \"process_refund\":\n",
    "                        result = self.process_refund(\n",
    "                            function_args[\"order_id\"],\n",
    "                            function_args[\"amount\"],\n",
    "                            function_args[\"reason\"]\n",
    "                        )\n",
    "                    elif function_name == \"escalate_to_human\":\n",
    "                        result = self.escalate_to_human(\n",
    "                            function_args[\"reason\"],\n",
    "                            function_args.get(\"priority\", \"medium\")\n",
    "                        )\n",
    "                    else:\n",
    "                        result = {\"error\": f\"Unknown function: {function_name}\"}\n",
    "                    \n",
    "                    # Add function result to messages\n",
    "                    messages.append({\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": json.dumps(result)\n",
    "                    })\n",
    "            else:\n",
    "                return assistant_message.content, messages\n",
    "        \n",
    "        return \"Maximum iterations reached\", messages\n",
    "\n",
    "# Create customer service agent\n",
    "cs_agent = CustomerServiceAgent(openai_client)\n",
    "print(\"✅ Customer Service Agent created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a5b64",
   "metadata": {},
   "source": [
    "### Test Customer Service Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "077a013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Test Scenario 1 ====================\n",
      "Customer: Hi, I'd like to check the status of my order ORD-123\n",
      "------------------------------------------------------------\n",
      "🔧 Using tool: lookup_order\n",
      "Agent: Your order **ORD-123** has been shipped! Here are the details:\n",
      "\n",
      "- **Items**: \n",
      "  - Wireless Laptop\n",
      "  - Gaming Mouse\n",
      "- **Total Amount**: $1299.99\n",
      "- **Tracking Number**: TRK-456789\n",
      "- **Shipped Date**: January 15, 2024\n",
      "\n",
      "If you have any more questions or need further assistance, feel free to ask!\n",
      "(Conversation had 5 messages)\n",
      "\n",
      "==================== Test Scenario 2 ====================\n",
      "Customer: I received order ORD-456 but the headphones don't work. I'd like a refund.\n",
      "------------------------------------------------------------\n",
      "Agent: I'm sorry to hear that the headphones you received are not working. I can help you with the refund process. \n",
      "\n",
      "Before we proceed, could you please confirm the following details for me?\n",
      "\n",
      "1. The order ID: ORD-456\n",
      "2. The amount you would like to be refunded (if it's the full price, please let me know).\n",
      "3. The reason for the refund (you can simply say \"defective\" if that applies).\n",
      "\n",
      "Once I have this information, I can process the refund for you.\n",
      "(Conversation had 3 messages)\n",
      "\n",
      "==================== Test Scenario 3 ====================\n",
      "Customer: My order ORD-999 never arrived and it's been 2 weeks. This is very frustrating!\n",
      "------------------------------------------------------------\n",
      "🔧 Using tool: lookup_order\n",
      "Agent: It seems that I couldn't find any information related to the order ID ORD-999. It's possible that there was a mistake in the order ID or that it hasn't been processed correctly.\n",
      "\n",
      "Could you please double-check the order ID for me? If you have any other details about the order, such as the items you ordered or the date of purchase, that would be helpful as well.\n",
      "(Conversation had 5 messages)\n"
     ]
    }
   ],
   "source": [
    "# Test scenarios for customer service agent\n",
    "test_scenarios = [\n",
    "    \"Hi, I'd like to check the status of my order ORD-123\",\n",
    "    \"I received order ORD-456 but the headphones don't work. I'd like a refund.\",\n",
    "    \"My order ORD-999 never arrived and it's been 2 weeks. This is very frustrating!\"\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\n{'='*20} Test Scenario {i} {'='*20}\")\n",
    "    print(f\"Customer: {scenario}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    response, conversation = cs_agent.handle_customer_request(scenario)\n",
    "    \n",
    "    print(f\"Agent: {response}\")\n",
    "    print(f\"(Conversation had {len(conversation)} messages)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977b04f",
   "metadata": {},
   "source": [
    "The prompt and response messages are automatically logged to Opik and can be viewed in the UI.\n",
    "\n",
    "![Openai Agents Opik Integration Handel Customer](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/openai_agents_opik_integration_cookbook_handel_customer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd36cd",
   "metadata": {},
   "source": [
    "### Agent Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5b8ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Calling function: web_search\n",
      "📝 Arguments: {'query': 'recent AI developments 2023'}\n",
      "✅ Function result: Search results for 'recent AI developments 2023': General information about the topic with recent de...\n",
      "Input: What are recent AI developments?\n",
      "Score: 0.75\n",
      "Expected keywords: ['AI', 'research', 'development', 'recent']\n",
      "----------------------------------------\n",
      "🔧 Using tool: lookup_order\n",
      "Input: Check order ORD-123 status\n",
      "Score: 1.00\n",
      "Expected keywords: ['order', 'status', 'ORD-123']\n",
      "----------------------------------------\n",
      "Input: I need help with a refund\n",
      "Score: 1.00\n",
      "Expected keywords: ['refund', 'help', 'process']\n",
      "----------------------------------------\n",
      "\n",
      "📊 Average Performance Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from opik.evaluation.metrics import LevenshteinRatio, Contains\n",
    "from opik import evaluate\n",
    "\n",
    "def evaluate_agent_responses():\n",
    "    \"\"\"Evaluate agent performance using Opik's evaluation framework\"\"\"\n",
    "    \n",
    "    # Test dataset for evaluation\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"input\": \"What are recent AI developments?\",\n",
    "            \"expected_keywords\": [\"AI\", \"research\", \"development\", \"recent\"]\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Check order ORD-123 status\",\n",
    "            \"expected_keywords\": [\"order\", \"status\", \"ORD-123\"]\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"I need help with a refund\",\n",
    "            \"expected_keywords\": [\"refund\", \"help\", \"process\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Custom evaluation metric\n",
    "    def contains_keywords(output: str, expected_keywords: List[str]) -> float:\n",
    "        \"\"\"Check if output contains expected keywords\"\"\"\n",
    "        output_lower = output.lower()\n",
    "        found_keywords = sum(1 for keyword in expected_keywords if keyword.lower() in output_lower)\n",
    "        return found_keywords / len(expected_keywords)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        # Run agent\n",
    "        if \"order\" in test_case[\"input\"].lower():\n",
    "            response, _ = cs_agent.handle_customer_request(test_case[\"input\"])\n",
    "        else:\n",
    "            response, _ = run_simple_agent(test_case[\"input\"])\n",
    "        \n",
    "        # Evaluate response\n",
    "        score = contains_keywords(response, test_case[\"expected_keywords\"])\n",
    "        \n",
    "        results.append({\n",
    "            \"input\": test_case[\"input\"],\n",
    "            \"output\": response,\n",
    "            \"score\": score,\n",
    "            \"expected_keywords\": test_case[\"expected_keywords\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"Input: {test_case['input']}\")\n",
    "        print(f\"Score: {score:.2f}\")\n",
    "        print(f\"Expected keywords: {test_case['expected_keywords']}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    avg_score = sum(r[\"score\"] for r in results) / len(results)\n",
    "    print(f\"\\n📊 Average Performance Score: {avg_score:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "evaluation_results = evaluate_agent_responses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b90dc42",
   "metadata": {},
   "source": [
    "The prompt and response messages are automatically logged to Opik and can be viewed in the UI.\n",
    "\n",
    "![Openai Agents Opik Integration Agent Performance](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/openai_agents_opik_integration_cookbook_agent_performance.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd8d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 View Your Agent Traces in Opik:\n",
      "==================================================\n",
      "1. Go to https://www.comet.com/\n",
      "2. Navigate to your Opik project: 'openai-agents-cookbook'\n",
      "3. Explore the traces to see:\n",
      "   • Agent conversations and tool usage\n",
      "   • Performance metrics and timing\n",
      "   • Token usage and costs\n",
      "   • Function call patterns\n",
      "\n",
      "💡 Tips for Analysis:\n",
      "   • Filter traces by project name\n",
      "   • Compare different agent implementations\n",
      "   • Monitor tool usage patterns\n",
      "   • Track performance over time\n"
     ]
    }
   ],
   "source": [
    "# Instructions for viewing results in Opik\n",
    "print(\"🎯 View Your Agent Traces in Opik:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. Go to https://www.comet.com/\")\n",
    "print(\"2. Navigate to your Opik project: 'openai-agents-cookbook'\")\n",
    "print(\"3. Explore the traces to see:\")\n",
    "print(\"   • Agent conversations and tool usage\")\n",
    "print(\"   • Performance metrics and timing\")\n",
    "print(\"   • Token usage and costs\")\n",
    "print(\"   • Function call patterns\")\n",
    "print(\"\\n💡 Tips for Analysis:\")\n",
    "print(\"   • Filter traces by project name\")\n",
    "print(\"   • Compare different agent implementations\")\n",
    "print(\"   • Monitor tool usage patterns\")\n",
    "print(\"   • Track performance over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f68e3",
   "metadata": {},
   "source": [
    "## Advanced Features - Custom Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373aaf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Calling function: web_search\n",
      "📝 Arguments: {'query': 'latest trends in machine learning 2024'}\n",
      "✅ Function result: Latest ML trends include transformer architectures, multimodal models, and efficient training techni...\n",
      "🎯 Agent Response with Custom Metadata:\n",
      "As of 2024, several key trends are shaping the landscape of machine learning:\n",
      "\n",
      "1. **Transformer Architectures**: Transformers continue to dominate many NLP and computer vision tasks due to their superior performance and scalability. These models are being adapted for various applications beyond their original design.\n",
      "\n",
      "2. **Multimodal Models**: There is an increasing focus on models that can process and integrate multiple types of data (e.g., text, images, audio) simultaneously. This trend is driven by the need for more comprehensive understanding and generation of content across different media.\n",
      "\n",
      "3. **Efficient Training Techniques**: As models grow larger, there is a growing emphasis on developing more efficient training methods. Techniques such as pruning, quantization, and knowledge distillation are being explored to reduce computational requirements without sacrificing performance.\n",
      "\n",
      "4. **Ethics and Explainability**: With the increasing deployment of machine learning systems, there is a stronger emphasis on ethical considerations and the need for explainable AI. Researchers and organizations are focusing on developing transparent models that can provide insights into their decision-making processes.\n",
      "\n",
      "5. **Federated Learning**: This approach allows models to be trained on decentralized data, enhancing privacy and security while enabling collaborative learning across different devices or organizations.\n",
      "\n",
      "6. **AutoML and ML Ops**: There is a move towards automation in model selection, hyperparameter tuning, and deployment processes, commonly referred to as AutoML. Additionally, ML Ops is becoming essential for managing the lifecycle of machine learning models in production environments.\n",
      "\n",
      "7. **Generative AI**: The rise of generative models, particularly in content creation (like text, images, and music), is a significant trend. These models are being used in creative industries and for generating synthetic data for training.\n",
      "\n",
      "These trends indicate a continued evolution in machine learning, focusing on efficiency, integration, and ethical use of technology.\n"
     ]
    }
   ],
   "source": [
    "@track(\n",
    "    project_name=\"openai-agents-cookbook\",\n",
    "    tags=[\"advanced\", \"metadata\"],\n",
    "    metadata={\"agent_type\": \"research\", \"version\": \"1.0\"}\n",
    ")\n",
    "def research_agent_with_metadata(query: str, user_id: str = \"demo_user\"):\n",
    "    \"\"\"Research agent with custom metadata tracking\"\"\"\n",
    "    \n",
    "    # Run the agent with the query\n",
    "    response, conversation = run_simple_agent(query)\n",
    "    \n",
    "    # The @track decorator will automatically capture the function's input and output\n",
    "    # Additional metadata is already set in the decorator above\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test with custom metadata\n",
    "result = research_agent_with_metadata(\n",
    "    \"What are the latest trends in machine learning?\", \n",
    "    user_id=\"researcher_001\"\n",
    ")\n",
    "\n",
    "print(\"🎯 Agent Response with Custom Metadata:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97cc12",
   "metadata": {},
   "source": [
    "The prompt and response messages are automatically logged to Opik and can be viewed in the UI.\n",
    "\n",
    "![openai agents opik Integration  Research Agent](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/openai_agents_opik_integration_cookbook_research_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "982e996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 OpenAI Agents + Opik Integration Complete!\n",
      "============================================================\n",
      "\n",
      "✅ What we've covered:\n",
      "1. Basic agent setup with Opik tracking\n",
      "2. Simple research agent with tool usage\n",
      "3. Multi-turn conversation handling\n",
      "4. Customer service agent implementation\n",
      "5. Performance evaluation and metrics\n",
      "6. Custom metadata and tagging\n",
      "\n",
      "📊 Key Benefits of Opik Integration:\n",
      "• Complete visibility into agent conversations\n",
      "• Tool usage tracking and analysis\n",
      "• Performance monitoring and optimization\n",
      "• Cost tracking and budgeting\n",
      "• Debug capabilities for complex workflows\n",
      "\n",
      "🚀 Next Steps:\n",
      "• Explore the Opik dashboard for detailed analytics\n",
      "• Implement custom evaluation metrics\n",
      "• Set up alerts for performance monitoring\n",
      "• Scale to production with proper error handling\n",
      "• Integrate with your existing agent workflows\n",
      "\n",
      "📈 Session Summary:\n",
      "• Project: openai-agents-cookbook\n",
      "• Agents tested: Research Agent, Customer Service Agent\n",
      "• Tools implemented: 3 research tools + 3 customer service tools\n"
     ]
    }
   ],
   "source": [
    "print(\"🎉 OpenAI Agents + Opik Integration Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n✅ What we've covered:\")\n",
    "print(\"1. Basic agent setup with Opik tracking\")\n",
    "print(\"2. Simple research agent with tool usage\")\n",
    "print(\"3. Multi-turn conversation handling\")\n",
    "print(\"4. Customer service agent implementation\")\n",
    "print(\"5. Performance evaluation and metrics\")\n",
    "print(\"6. Custom metadata and tagging\")\n",
    "\n",
    "print(\"\\n📊 Key Benefits of Opik Integration:\")\n",
    "print(\"• Complete visibility into agent conversations\")\n",
    "print(\"• Tool usage tracking and analysis\")\n",
    "print(\"• Performance monitoring and optimization\")\n",
    "print(\"• Cost tracking and budgeting\")\n",
    "print(\"• Debug capabilities for complex workflows\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"• Explore the Opik dashboard for detailed analytics\")\n",
    "print(\"• Implement custom evaluation metrics\")\n",
    "print(\"• Set up alerts for performance monitoring\")\n",
    "print(\"• Scale to production with proper error handling\")\n",
    "print(\"• Integrate with your existing agent workflows\")\n",
    "\n",
    "print(f\"\\n📈 Session Summary:\")\n",
    "print(f\"• Project: openai-agents-cookbook\")\n",
    "print(f\"• Agents tested: Research Agent, Customer Service Agent\")\n",
    "print(f\"• Tools implemented: {len(tools)} research tools + 3 customer service tools\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
